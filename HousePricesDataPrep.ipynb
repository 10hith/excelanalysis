{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5c0805-de69-4778-97e0-9731dd908624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n",
      "Warning: Ignoring non-Spark config property: driver-class-path\n",
      "22/02/25 18:38:59 WARN Utils: Your hostname, DESKTOP-9QGN9QQ resolves to a loopback address: 127.0.1.1; using 172.21.85.55 instead (on interface eth0)\n",
      "22/02/25 18:38:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/02/25 18:39:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from utils.spark_utils import get_local_spark_session\n",
    "from utils.spark_utils import cleanup_col_name, with_std_column_names\n",
    "\n",
    "spark = get_local_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1fff32-e956-40e5-90e0-8089ec50d44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.85.55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GeoSpatial Application</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9377d4aac0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0f09f-b6cb-4790-931d-296d029951b5",
   "metadata": {},
   "source": [
    "**Read postcode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce0da89e-f107-4e9a-800a-14efbafff989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- postcode_geo: geometry (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from utils.spark_utils import cleanup_col_name, with_std_column_names\n",
    "\n",
    "postcode_df = spark.read.format('csv').option(\"header\", \"true\").load(\"/mnt/c/users/lohith/Downloads/National_Statistics_Postcode_Lookup_UK_Coordinates.csv\")\n",
    "# postcode_df.printSchema()\n",
    "\n",
    "postcode_df = postcode_df\\\n",
    ".filter(\"latitude IS NOT NULL OR longitude IS NOT NULL\")\\\n",
    ".transform(with_std_column_names())\\\n",
    ".withColumn(\"postcode_geo\",f.expr(\n",
    "    \"\"\" ST_Transform(ST_Point(CAST(latitude AS DOUBLE), CAST(longitude AS DOUBLE)), 'epsg:4326', 'epsg:3857')\"\"\")\n",
    "           )\\\n",
    ".selectExpr(\n",
    "    \"postcode_3 as postcode\",\n",
    "    \"CAST(latitude AS DOUBLE) as lat\",\n",
    "    \"CAST(longitude AS DOUBLE) as lon\",\n",
    "    \"postcode_geo\"\n",
    ")\n",
    "\n",
    "postcode_df.printSchema()\n",
    "# postcode_df.createOrReplaceTempView(\"postcode_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be8c32c-153d-4c54-9ac2-6db9fe531f96",
   "metadata": {},
   "source": [
    "**Read housePrices data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3f8c03d-797f-4ad2-8442-e27c11ebb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from typing import List\n",
    "\n",
    "monthly_file_schema = StructType([\n",
    "StructField('id',StringType(),True),\n",
    "StructField('price',StringType(),True),\n",
    "StructField('dt',StringType(),True),\n",
    "StructField('postcode',StringType(),True),\n",
    "StructField('type',StringType(),True),\n",
    "StructField('new_flag',StringType(),True),\n",
    "StructField('duration',StringType(),True),\n",
    "StructField('poan',StringType(),True),\n",
    "StructField('soan',StringType(),True),\n",
    "StructField('street',StringType(),True),\n",
    "StructField('locality',StringType(),True),\n",
    "StructField('town',StringType(),True),\n",
    "StructField('district',StringType(),True),\n",
    "StructField('county',StringType(),True),\n",
    "StructField('price_paid',StringType(),True),\n",
    "StructField('record_status',StringType(),True),\n",
    "])\n",
    "hp_raw = spark.read.format('csv')\\\n",
    ".option(\"header\", \"false\")\\\n",
    ".schema(monthly_file_schema)\\\n",
    ".load(f\"/mnt/c/users/lohith/Downloads/housePriceRaw/\")\n",
    "\n",
    "hp = hp_raw.transform(with_std_column_names())\\\n",
    ".selectExpr(\n",
    "    \"postcode\",\n",
    "    \"CAST(dt AS DATE) dt\", \n",
    "    \"type\", \n",
    "    \"poan\",\n",
    "    \"CAST(price AS INT) as price\", \n",
    "    \"street\",\n",
    "    \"town\",\n",
    "    \"district\",\n",
    "    \"county\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58586c35-f704-4dd2-9ac5-fc2e4fd90a0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhp\u001b[49m\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hp' is not defined"
     ]
    }
   ],
   "source": [
    "hp.sort(\"dt\",\"type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8df146-9504-49ca-a0ee-d832a0defb65",
   "metadata": {},
   "source": [
    "\n",
    "**Write HousePrices with geom column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "598a3b45-c26d-458a-bd01-7821deea96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hp\\\n",
    ".filter(\"postcode IS NOT NULL\")\\\n",
    ".join(postcode_df,\"postcode\",'inner')\\\n",
    ".withColumn(\"postcode\",f.expr(\"regexp_replace(postcode, ' ', '')\"))\\\n",
    ".sort(\"lat\", \"lon\")\\\n",
    ".repartition(4,'postcode_geo')\\\n",
    ".write.mode(\"overwrite\")\\\n",
    ".save(\"/mnt/c/users/lohith/Downloads/house_price_lkp/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dddf9e-ac54-424d-8d8f-c68eded3a4dd",
   "metadata": {},
   "source": [
    "**Prepare for the app run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6fd28c48-2aae-4b61-a765-9382998c100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "house_price_lkp = spark.read.load(\"/mnt/c/users/lohith/Downloads/house_price_lkp/\")\n",
    "post_code='BR6 6DN'\n",
    "pdf = house_price_lkp\\\n",
    ".selectExpr('postcode','lat', 'lon').distinct().toPandas()\n",
    "\n",
    "pdf_index = pdf.set_index('postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "eba4db87-00ba-4bd3-810d-84f7022c8ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3e25b6f9-cc17-44cc-8371-3105f08c17ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[postcode: string, dt: date, type: string, poan: string, price: double, street: string, town: string, district: string, county: string, lat: double, lon: double, postcode_geo: udt]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_price_lkp.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "0729c8e2-86c7-4080-9308-70b18cf89b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/26 00:44:49 WARN CacheManager: Asked to cache already cached data.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "house_price_lkp = house_price_lkp.filter(\"year(dt)='2020'\").cache()\n",
    "house_price_lkp.take(1)\n",
    "house_price_lkp.createOrReplaceTempView(\"housePriceLkp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ca60857b-2c9b-4b42-ad8f-9d193613b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (lkp_lat,lkp_lon) = (59.37707668858785, -1.4762877837637978)\n",
    "(lkp_lat,lkp_lon) = (51.574968, 0.088584)\n",
    "# (lkp_lat,lkp_lon) = (53.80338074459603, -1.5591111308414478)\n",
    "\n",
    "\n",
    "def get_house_prices(lkp_lat, lkp_lon):\n",
    "    df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "    lat,\n",
    "    lon,\n",
    "    postcode,\n",
    "    dt, \n",
    "    type, \n",
    "    price, \n",
    "    street,\n",
    "    town,\n",
    "    district,\n",
    "    county,\n",
    "    ST_Distance(\n",
    "        postcode_geo,\n",
    "        ST_Transform(ST_Point({lkp_lat},{lkp_lon}),'epsg:4326', 'epsg:3857')\n",
    "        )/1609 AS distance_in_km\n",
    "    FROM \n",
    "    housePriceLkp\n",
    "    WHERE ST_Distance(\n",
    "        postcode_geo,\n",
    "        ST_Transform(ST_Point({lkp_lat},{lkp_lon}),'epsg:4326', 'epsg:3857')\n",
    "        )/1609 < .5   \n",
    "    \"\"\")\n",
    "    df = df.withColumn(\"tooltip\",f.expr(\n",
    "        \"\"\"CONCAT('Â£',price, '-', type, '-', dt) \"\"\")\n",
    "                       )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# if get_house_prices(lkp_lat, lkp_lon).take(1):\n",
    "#     print(1)\n",
    "\n",
    "# get_house_prices(lkp_lat, lkp_lon).show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "03fc9c2e-389b-45eb-8d27-5fd9943d06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# house_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a7f648-bdc4-4f61-b849-e11a46303bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html\n",
    "import dash_leaflet.express as dlx\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_leaflet as dl\n",
    "from dash.exceptions import PreventUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "edfd1d2c-cdd9-42fd-afcd-415c727f81cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.38379531261044 0.06820827323898106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.38025564916925 0.09792020160503068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "app = JupyterDash(__name__, \n",
    "                prevent_initial_callbacks=True,\n",
    "                suppress_callback_exceptions=True,)\n",
    "\n",
    "icons ={ \n",
    "    \"iconUrl\": 'https://raw.githubusercontent.com/pointhi/leaflet-color-markers/master/img/marker-icon-2x-yellow.png',\n",
    "    \"shadowUrl\": 'https://cdnjs.cloudflare.com/ajax/libs/leaflet/0.7.7/images/marker-shadow.png',\n",
    "    \"iconSize\": [25, 41],\n",
    "    \"iconAnchor\": [12, 41],\n",
    "    \"popupAnchor\": [1, -34],\n",
    "    \"shadowSize\": [41, 41]\n",
    "    }\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    \n",
    "    dbc.Row(\n",
    "        dbc.Col([\n",
    "            html.Br(),\n",
    "            html.Br(),\n",
    "            postCodeIp := dcc.Input(placeholder=\"Input your postcode here\"),\n",
    "            submitButton := dbc.Button(\"Submit\"),\n",
    "            html.Br(),\n",
    "            alertDummyContainer := html.Div(),\n",
    "            alertDummyContainer1 := html.Div(),\n",
    "            dcc.Store(id=\"inputLatLonStore\")\n",
    "        ])\n",
    "    ),\n",
    "    dbc.Row(\n",
    "        dbc.Col([\n",
    "            myMap := dl.Map([\n",
    "                    dl.TileLayer(),\n",
    "                    dl.LayerGroup(id=\"layer\"),\n",
    "                    dl.LayerGroup(id=\"housePriceLayer\"),\n",
    "                    dl.LayerGroup(id=\"housePriceLayerOnMapClick\"),\n",
    "                    # dl.LocateControl(options={'locateOptions': {'enableHighAccuracy': True}}),\n",
    "                ], id=\"map\",\n",
    "                center=(51.354221748320946, 0.09599384789215022),\n",
    "                zoom=15,\n",
    "                style={'width': '100%', 'height': '50vh', 'margin': \"auto\", \"display\": \"block\"}),\n",
    "        ])\n",
    "    ),\n",
    "], fluid=True)\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"housePriceLayerOnMapClick\", \"children\"),\n",
    "    [Input(\"map\", \"click_lat_lng\")],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def get_nearby_houses_on_mapclick(click_lat_lng):\n",
    "    (lkp_lat,lkp_lon) = click_lat_lng[0], click_lat_lng[1]\n",
    "    print(lkp_lat,lkp_lon)\n",
    "    house_price_sdf = get_house_prices(lkp_lat,lkp_lon)\n",
    "    \n",
    "    house_price_pdf = house_price_sdf.toPandas()\n",
    "    house_point = house_price_pdf.to_dict('records')\n",
    "        \n",
    "    if len(house_point)==0:\n",
    "        return []\n",
    "    \n",
    "    house_price_on_map_click = dl.GeoJSON(\n",
    "        id=\"someId\",\n",
    "        data=dlx.dicts_to_geojson(\n",
    "            house_point,\n",
    "        ),\n",
    "        cluster=True,\n",
    "        )\n",
    "    \n",
    "    return house_price_on_map_click\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"housePriceLayer\", \"children\"),\n",
    "    Input(\"inputLatLonStore\",\"data\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def get_nearby_houses_on_postcode(latlon):\n",
    "    if len(latlon)==0:\n",
    "        raise PreventUpdate\n",
    "        return []\n",
    "        \n",
    "    (lkp_lat,lkp_lon) = latlon[0].values()\n",
    "    house_price_sdf = get_house_prices(lkp_lat,lkp_lon)\n",
    "    \n",
    "    house_price_pdf = house_price_sdf.toPandas()\n",
    "    house_point = house_price_pdf.to_dict('records')\n",
    "        \n",
    "    if len(house_point)==0:\n",
    "        return []\n",
    "    \n",
    "    house_price_layer = dl.GeoJSON(\n",
    "        id=\"someId\",\n",
    "        data=dlx.dicts_to_geojson(\n",
    "            house_point,\n",
    "        ),\n",
    "        cluster=True,\n",
    "        )\n",
    "    \n",
    "    return house_price_layer\n",
    "\n",
    "@app.callback(\n",
    "    Output(alertDummyContainer, \"children\"),\n",
    "    Output(\"layer\", \"children\"),\n",
    "    Output(myMap, \"center\"),\n",
    "    Output(\"inputLatLonStore\", \"data\"),\n",
    "    Input(submitButton, \"n_clicks\"),\n",
    "    State(postCodeIp, \"value\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def displayPostCodeOnMap(n_clicks, post_code):\n",
    "    post_code = post_code.replace(\" \", \"\").upper()\n",
    "    \n",
    "    try:\n",
    "        (lat,lon) = pdf_index.loc[post_code][['lat','lon']]\n",
    "    except KeyError:\n",
    "            print(\"Post code not found\")\n",
    "            alert =  dbc.Alert(\"Post Code NOT FOUND !!!\", id=\"alert-auto\", is_open=True, duration=3000),\n",
    "            return alert, [], (51.354221748320946, 0.09599384789215022), []\n",
    "  \n",
    "    marker = dl.Marker(\n",
    "        position=[lat, lon], children=dl.Tooltip(f\"{post_code}\"), icon=icons\n",
    "    )\n",
    "    return [], [marker], (lat, lon), [{'lat':lat,'lon':lon}]\n",
    "\n",
    "app.run_server(mode='external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d8d97bd-9542-4322-9334-da2f06a7099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "import dash_leaflet as dl\n",
    "import dash_leaflet.express as dlx\n",
    "from dash import Dash, html\n",
    "from dash_extensions.javascript import assign\n",
    "from utils.params import HOST\n",
    "\n",
    "\n",
    "# A few countries.\n",
    "countries = [dict(name=\"Denmark\", iso2=\"dk\", lat=56.26392, lon=9.501785),\n",
    "             dict(name=\"Sweden\", iso2=\"se\", lat=59.334591, lon=18.063240),\n",
    "             dict(name=\"Norway\", iso2=\"no\", lat=59.911491, lon=9.501785)]\n",
    "# Generate geojson with a marker for each country and name as tooltip.\n",
    "geojson = dlx.dicts_to_geojson([{**c, **dict(tooltip=c['name'])} for c in countries])\n",
    "# Create javascript function that draws a marker with a custom icon, in this case a flag hosted by flagcdn.\n",
    "draw_flag = assign(\"\"\"function(feature, latlng){\n",
    "const flag = L.icon({iconUrl: 'https://raw.githubusercontent.com/pointhi/leaflet-color-markers/master/img/marker-icon-2x-yellow.png', iconSize: [64, 48]});\n",
    "return L.marker(latlng, {icon: flag});\n",
    "}\"\"\")\n",
    "\n",
    "# draw_flag = assign(\"\"\"function(feature, latlng){\n",
    "# const flag = L.icon({iconUrl: `https://flagcdn.com/64x48/${feature.properties.iso2}.png`, iconSize: [64, 48]});\n",
    "# return L.marker(latlng, {icon: flag});\n",
    "# }\"\"\")\n",
    "# Create example app.\n",
    "app = JupyterDash()\n",
    "app.layout = html.Div([\n",
    "    dl.Map(children=[\n",
    "        dl.TileLayer(), dl.GeoJSON(data=geojson, options=dict(pointToLayer=draw_flag), zoomToBounds=True)\n",
    "    ], style={'width': '100%', 'height': '50vh', 'margin': \"auto\", \"display\": \"block\"}, id=\"map\"),\n",
    "])\n",
    "\n",
    "\n",
    "app.run_server(mode=\"external\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
